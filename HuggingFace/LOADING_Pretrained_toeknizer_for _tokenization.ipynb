{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e81902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "raw_inputs = [\"ilove you so much\" , \"i hate you\"]\n",
    "\n",
    "inputs = tokenizer(raw_inputs,padding=True,truncation=True,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199e1e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  6335, 21818,  2017,  2061,  2172,   102],\n",
       "        [  101,  1045,  5223,  2017,   102,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee683d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "outputs= model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926924ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 0.3680,  0.3678,  0.6209,  ...,  0.3771,  0.6945, -0.4780],\n",
       "         [ 0.7431,  0.6132,  0.6627,  ...,  0.4176,  0.7071, -0.1878],\n",
       "         [ 0.7786,  0.6371,  0.8122,  ...,  0.4311,  0.7185, -0.4775],\n",
       "         ...,\n",
       "         [ 0.5509,  0.4597,  0.5705,  ...,  0.4198,  0.6605, -0.2047],\n",
       "         [ 0.5637,  0.5561,  0.5104,  ...,  0.4693,  0.5792, -0.3912],\n",
       "         [ 1.2893,  0.4482,  0.8858,  ...,  0.6921,  0.3001, -0.8209]],\n",
       "\n",
       "        [[-0.3473,  0.8337, -0.4560,  ..., -0.2185, -0.7385, -0.0927],\n",
       "         [-0.1072,  1.1280, -0.4087,  ..., -0.4267, -0.4758,  0.1905],\n",
       "         [-0.0195,  1.0290, -0.4657,  ..., -0.4203, -0.5142,  0.1062],\n",
       "         ...,\n",
       "         [ 0.1300,  0.2511, -0.3323,  ..., -0.0435, -0.5050, -0.2333],\n",
       "         [-0.4336,  0.9010, -0.6294,  ..., -0.2681, -0.4861, -0.0689],\n",
       "         [-0.3649,  0.7879, -0.4833,  ..., -0.1482, -0.5317, -0.1488]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89d3ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state.size()) # batch_size , Sequence_length , Hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5376a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "logits= model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4f1098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.7309,  4.0196],\n",
       "        [ 3.8724, -3.1543]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3286a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "prediction = torch.nn.functional.softmax(logits.logits,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85b8dc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3034e-04, 9.9957e-01],\n",
       "        [9.9911e-01, 8.8707e-04]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2544fff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd03ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
