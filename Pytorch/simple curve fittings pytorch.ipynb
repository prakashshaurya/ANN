{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3a0845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: y = -0.0129076122171402 + 0.8385843215198399 x + 0.0022267778910510768 x^2 + -0.09074778195793097 x^3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = np.linspace(-math.pi,math.pi,2000) # define x values\n",
    "y = np.sin(x)                          # define y functon that will take x as input\n",
    "\n",
    "a= np.random.randn()\n",
    "c= np.random.randn()\n",
    "b= np.random.randn()\n",
    "d= np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(2000) :\n",
    "    \n",
    "    ypred = a + b*x + c*x**2 + d*x**3\n",
    "    loss  =  np.square(ypred-y).sum()\n",
    "    \n",
    "    grad_ypred = 2*(ypred-y)  \n",
    "    grad_a = (grad_ypred).sum()      # d (loss) / da  = 2*(ypred-y) *  d( a + b*x + c*x**2 + d*x**3)/da \n",
    "    grad_b = (grad_ypred*x).sum()    # d (loss) / db  = 2*(ypred-y) *  d( a + b*x + c*x**2 + d*x**3)/db \n",
    "    grad_c = (grad_ypred*x**2).sum() # d (loss) / dc  = 2*(ypred-y) *  d( a + b*x + c*x**2 + d*x**3)/dc \n",
    "    grad_d = (grad_ypred*x**3).sum() # d (loss) / dd  = 2*(ypred-y) *  d( a + b*x + c*x**2 + d*x**3)/dd\n",
    "\n",
    "    \n",
    "    a -= learning_rate * grad_a   # a =  a -{ d (loss) / da }*learning_rate\n",
    "    b -= learning_rate * grad_b   # b =  b -{ d (loss) / db }*learning_rate\n",
    "    c -= learning_rate * grad_c   # c =  c -{ d (loss) / dc }*learning_rate\n",
    "    d -= learning_rate * grad_d   # d =  d -{ d (loss) / dd }*learning_rate\n",
    "    \n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45d89123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 3060.302490234375\n",
      "199 2027.9462890625\n",
      "299 1344.916259765625\n",
      "399 892.9852294921875\n",
      "499 593.948974609375\n",
      "599 396.0722351074219\n",
      "699 265.1278076171875\n",
      "799 178.47117614746094\n",
      "899 121.12026977539062\n",
      "999 83.16217041015625\n",
      "1099 58.03750991821289\n",
      "1199 41.40628433227539\n",
      "1299 30.396650314331055\n",
      "1399 23.10767364501953\n",
      "1499 18.281721115112305\n",
      "1599 15.086213111877441\n",
      "1699 12.970084190368652\n",
      "1799 11.568595886230469\n",
      "1899 10.640286445617676\n",
      "1999 10.025369644165039\n",
      "result = -0.006736767012625933 + 0.8235231637954712 * x + 0.0011622037272900343 * x**2 + -0.08860546350479126 * x**3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "dtype =  torch.float\n",
    "\n",
    "# Create random learning rate\n",
    "learning_rate = 1e-6\n",
    "\n",
    "# Create random weights\n",
    "a = torch.randn(() , device=device , dtype=dtype)\n",
    "b = torch.randn(() , device=device , dtype=dtype)\n",
    "c = torch.randn(() , device=device , dtype=dtype)\n",
    "d = torch.randn(() , device=device , dtype=dtype)\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi ,math.pi ,2000)\n",
    "y= torch.sin(x)\n",
    "\n",
    "for t in range(2000) :\n",
    "    \n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "    \n",
    "    #loss\n",
    "    \n",
    "    loss = (y_pred-y).pow(2).sum().item()\n",
    "    \n",
    "       # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'result = {a} + {b} * x + {c} * x**2 + {d} * x**3' )\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e5b1882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi,math.pi,2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "x.unsqueeze(-1).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a283d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf93a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca3168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
